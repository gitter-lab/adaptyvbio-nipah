{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf46772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in working directory:\n",
      "  2VSM.pdb\n",
      "  Surface-Plasmon-Resonance-Adaptyv-Bio-Docs.pdf\n",
      "  cdr_library_summary.csv\n",
      "  notebook.ipynb\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load necessary libraries and examine the available data files\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# List all files in the working directory\n",
    "print(\"Files in working directory:\")\n",
    "for file in sorted(os.listdir('.')):\n",
    "    if not file.startswith('.'):\n",
    "        print(f\"  {file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc29369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CDR Library Summary:\n",
      "   Antibody CDR Chain_Type           Sequence  Length           PDB_IDs  \\\n",
      "0       1E5  H1      Heavy         GGSISDTYRW      10  8K0C, 8K0D, 8XC4   \n",
      "1       1E5  H2      Heavy           IYGSATST       8  8K0C, 8K0D, 8XC4   \n",
      "2       1E5  H3      Heavy  ARDYQYYYSGSYPTPHN      17  8K0C, 8K0D, 8XC4   \n",
      "3       1E5  L1      Light       RASQGIIDYLSW      12  8K0C, 8K0D, 8XC4   \n",
      "4       1E5  L2      Light           TASNLESG       8  8K0C, 8K0D, 8XC4   \n",
      "5       1E5  L3      Light          LQGYTTPYT       9  8K0C, 8K0D, 8XC4   \n",
      "6      14F8  H1      Heavy         GFSLTSYDIS      10              8JA5   \n",
      "7      14F8  H2      Heavy           WTGGVTNY       8              8JA5   \n",
      "8      14F8  H3      Heavy              VREGD       5              8JA5   \n",
      "9      14F8  L1      Light       RSSQSIVHSNGN      12              8JA5   \n",
      "10     14F8  L2      Light           QLLIYKVS       8              8JA5   \n",
      "11     14F8  L3      Light          FQASHVPYT       9              8JA5   \n",
      "\n",
      "     Chains  Num_Instances  \n",
      "0   C, E, G              6  \n",
      "1   C, E, G              6  \n",
      "2   C, E, G              6  \n",
      "3   D, F, H              6  \n",
      "4   D, F, H              6  \n",
      "5   D, F, H              6  \n",
      "6      B, H              2  \n",
      "7      B, H              2  \n",
      "8      B, H              2  \n",
      "9      C, L              2  \n",
      "10     C, L              2  \n",
      "11     C, L              2  \n",
      "\n",
      "Total CDR sequences: 12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the CDR library summary to understand the structure\n",
    "cdr_library = pd.read_csv('cdr_library_summary.csv')\n",
    "print(\"CDR Library Summary:\")\n",
    "print(cdr_library.head(15))\n",
    "print(f\"\\nTotal CDR sequences: {len(cdr_library)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729b5a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available CSV files:\n",
      "  cdr_library_summary.csv\n",
      "\n",
      "Available FASTA files:\n",
      "  None found\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the top_50_nivg_binder_designs_final.csv file exists\n",
    "# If not, we need to understand what files are available\n",
    "import glob\n",
    "\n",
    "# Look for any CSV files that might contain the design data\n",
    "csv_files = glob.glob('*.csv')\n",
    "print(\"Available CSV files:\")\n",
    "for f in csv_files:\n",
    "    print(f\"  {f}\")\n",
    "\n",
    "# Look for any FASTA files\n",
    "fasta_files = glob.glob('*.fasta') + glob.glob('*.fa')\n",
    "print(\"\\nAvailable FASTA files:\")\n",
    "if fasta_files:\n",
    "    for f in fasta_files:\n",
    "        print(f\"  {f}\")\n",
    "else:\n",
    "    print(\"  None found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff83e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files in working directory:\n",
      "  ./.config/matplotlib/matplotlibrc\n",
      "  2VSM.pdb\n",
      "  Surface-Plasmon-Resonance-Adaptyv-Bio-Docs.pdf\n",
      "  cdr_library_summary.csv\n",
      "  notebook.ipynb\n",
      "\n",
      "Subdirectories:\n",
      "  None found\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# The required files are not in the directory, but they are listed as derived artifacts.\n",
    "# This suggests they may need to be retrieved or may have been uploaded under different names.\n",
    "# Let me check for any other files that might contain this data, including hidden files.\n",
    "\n",
    "# Check for all files including hidden ones\n",
    "all_files = []\n",
    "for root, dirs, files in os.walk('.'):\n",
    "    for file in files:\n",
    "        if root == '.':\n",
    "            all_files.append(file)\n",
    "        else:\n",
    "            all_files.append(os.path.join(root, file))\n",
    "\n",
    "print(\"All files in working directory:\")\n",
    "for f in sorted(all_files):\n",
    "    if 'ipynb_checkpoints' not in f:\n",
    "        print(f\"  {f}\")\n",
    "        \n",
    "# Check if there are any subdirectories\n",
    "print(\"\\nSubdirectories:\")\n",
    "subdirs = [d for d in os.listdir('.') if os.path.isdir(d) and not d.startswith('.')]\n",
    "if subdirs:\n",
    "    for d in subdirs:\n",
    "        print(f\"  {d}\")\n",
    "else:\n",
    "    print(\"  None found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0cda62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CRITICAL DATA AVAILABILITY ISSUE\n",
      "================================================================================\n",
      "\n",
      "I cannot complete this analysis because the required input files are missing:\n",
      "\n",
      "1. top_50_nivg_binder_designs_final.csv\n",
      "   - Status: Listed as a derived artifact but not present in working directory\n",
      "   - Required for: The 50 candidate binder designs to be filtered\n",
      "\n",
      "2. known_niv_binders.fasta\n",
      "   - Status: Referenced in task description but not present\n",
      "   - Required for: Database of known binder sequences for comparison\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS CANNOT PROCEED\n",
      "================================================================================\n",
      "\n",
      "To complete this task, both files must be provided in the working directory.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# The required input files (top_50_nivg_binder_designs_final.csv and known_niv_binders.fasta)\n",
    "# are not present in the working directory. These files are listed as derived artifacts\n",
    "# from previous analyses but are not available.\n",
    "\n",
    "# I cannot proceed with this analysis without the primary input data.\n",
    "# According to the core principles:\n",
    "# \"If a request is beyond your capabilities or the scope of provided data, \n",
    "# you must state this clearly and concisely.\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CRITICAL DATA AVAILABILITY ISSUE\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nI cannot complete this analysis because the required input files are missing:\")\n",
    "print(\"\\n1. top_50_nivg_binder_designs_final.csv\")\n",
    "print(\"   - Status: Listed as a derived artifact but not present in working directory\")\n",
    "print(\"   - Required for: The 50 candidate binder designs to be filtered\")\n",
    "print(\"\\n2. known_niv_binders.fasta\")\n",
    "print(\"   - Status: Referenced in task description but not present\")\n",
    "print(\"   - Required for: Database of known binder sequences for comparison\")\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ANALYSIS CANNOT PROCEED\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nTo complete this task, both files must be provided in the working directory.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
